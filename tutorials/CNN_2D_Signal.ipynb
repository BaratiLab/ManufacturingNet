{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developing a 2D Convolutional Neural Network (CNN) using ManufacturingNet\n",
    "###### To know more about the manufacturingnet please visit: http://manufacturingnet.io/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ManufacturingNet\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import manufacturingnet. Using manufacturingnet we can create different types of neural networks like CNNs with greater ease.\n",
    "\n",
    "It is important to note that all the dependencies of the package must also be installed in your environment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For any machine learning model the most important thing is the dataset. So we first need to download the data depending on the application. ManufacturingNet offers a dataset class where we have curated different types of datasets and you just need to run two lines of code to download the data :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ManufacturingNet import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Please be patient downloading the data may take some time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1z_2ceidvHmE5p7XCD4PaGn4ezvcZMxdD\n",
      "To: /home/cmu/ManufacturingNet/tutorials/ChatterData.zip\n",
      "100%|██████████| 86.3M/86.3M [00:06<00:00, 12.9MB/s]\n"
     ]
    }
   ],
   "source": [
    "datasets.ChatterData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Great! The data has been downloaded to your working directory. You can use to develop cool machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Turning chatter dataset is a vibration signals dataset with 4 classes. The classes are an indicator of the no-chatter, intermediate chatter, chatter, and unknown chatter. The dataset is useful to the userd who are interested in applying machine learning to machining datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### It is important to note that the path that the tutorial developer used in the below cell may be different than the user. The users will have figure it out if this bit of code does not work as is in their systems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets load the data\n",
    "X =  np.load('./Turning_chatter/raw_signal_data.npy', allow_pickle = True)\n",
    "Y = np.load('./Turning_chatter/signal_data_labels.npy', allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7058, 1600), (7058,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets check what is the shape of the data\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright we need to reshape the data to run the CNN2D signal. The CNN takes as input the data in form of channels, height, width. In the manufacturingnet paper we have used a size of 40,40 to get the results. So lets reshape all the datapoints X  to that (1,40,40)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(len(X),1,40,40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The next step is importing CNN2D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ManufacturingNet.models import CNN2DSignal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### We import the Deep Neural Network (DNNModel ) from package and answer a few simple questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/15 - Get 2D folded signal Size\n",
      "Please enter the size of the first dimension of the folded 2D signal: 40\n",
      "Please enter the size of the second dimension of the folded 2D signal: 40\n",
      "Image:  40 40\n",
      "=========================\n",
      "2/15 - Number of Convolutions\n",
      "Please enter the number of convolutions: 1\n",
      "Convolutions:  1\n",
      "=========================\n",
      "3/15 - Channels\n",
      "enter the number of input channels: 1\n",
      "enter the number of output channels for convolution 1: 16\n",
      "Channels:  [1, 16]\n",
      "=========================\n",
      "4/15 - Kernels\n",
      "Do you want default values for kernel size(press y or n): y\n",
      "Kernel sizes:  [(3, 3)]\n",
      "=========================\n",
      "5/15 - Padding and Stride\n",
      "Do you want default values for padding and stride (press y or n): y\n",
      "Padding:  [(0, 0)]\n",
      "Stride:  [(1, 1)]\n",
      "=========================\n",
      "6/15 - Dropout\n",
      "Do you want default values for dropout(press y or n): y\n",
      "Dropout ratio:  0.0\n",
      "=========================\n",
      "7/15 - Max Pooling\n",
      "Do you want default pooling values (press y or n): y\n",
      "Pooling Layers:  [1]\n",
      "Pooling Size:  [(2, 2)]\n",
      "Pooling Stride [(2, 2)]\n",
      "=========================\n",
      "8/15 - Batch Normalization\n",
      "Do you want default values for batch normalization (press y or n): y\n",
      "Batch normalization [1]\n",
      "=========================\n",
      "9/15 - Number of classes\n",
      "Please enter the number of classes \n",
      " Enter 1 if you are dealing with a regression problem: 4\n",
      "=========================\n",
      "Shapes after the Convolutions [(19, 19)]\n",
      "=========================\n",
      "10/15 - Batch size input\n",
      "Please enter the batch size: 1\n",
      "Batch Size:  1\n",
      "=========================\n",
      "11/15 - Validation set size\n",
      "Please enter the validation set size (size > 0 and size < 1) \n",
      " For default size, please directly press enter without any input: 0.2\n",
      "Validation set ratio:  0.2\n",
      "=========================\n",
      "12/15 - Loss function\n",
      "Please enter the appropriate loss function for the problem: \n",
      " Criterion_list - [1: CrossEntropyLoss, 2: L1Loss, 3: SmoothL1Loss, 4: MSELoss]: 1\n",
      "Loss Function:  CrossEntropyLoss()\n",
      "=========================\n",
      "13/15 - Optimizer\n",
      "Please enter the optimizer for the problem \n",
      " Optimizer_list - [1: Adam, 2: SGD] \n",
      " For default optimizer, please directly press enter without any input: 1\n",
      "Please enter a required postive value for learning rate \n",
      " For default learning rate, please directly press enter without any input: 0.0001\n",
      "Optimizer:  Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "=========================\n",
      "14/15 - Scheduler\n",
      "Please enter the scheduler for the problem: Scheduler_list - [1: None, 2:StepLR, 3:MultiStepLR] \n",
      " For default option of no scheduler, please directly press enter without any input: 1\n",
      "Scheduler:  None\n",
      "=========================\n",
      "15/15 - Number of epochs\n",
      "Please enter the number of epochs to train the model: 10\n",
      "Epochs:  10\n",
      "=========================\n",
      "Neural network architecture: \n",
      " \n",
      "CNN2D(\n",
      "  (ConvNet): Sequential(\n",
      "    (0): CNNBlock(\n",
      "      (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (1): Linear(in_features=5776, out_features=2888, bias=True)\n",
      "    (2): Linear(in_features=2888, out_features=1444, bias=True)\n",
      "    (3): Dropout(p=0.0, inplace=False)\n",
      "    (4): Linear(in_features=1444, out_features=4, bias=True)\n",
      "  )\n",
      ")\n",
      "=========================\n",
      "Model Summary:\n",
      " \n",
      "Criterion:  CrossEntropyLoss()\n",
      "Optimizer:  Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    lr: 0.0001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Scheduler:  None\n",
      "Validation set size:  0.2\n",
      "Batch size:  1\n",
      "Initial learning rate:  0.0001\n",
      "Number of training epochs:  10\n",
      "Device:  cuda\n",
      " \n",
      "=========================\n",
      "Training the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  0%|                                                                                                                                                                            | 0/10 [00:00<?, ?epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch_Number:  0\n",
      "Training Loss:  0.8411133036743331\n",
      "Training Accuracy:  72.19270279844137 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 10%|████████████████▎                                                                                                                                                  | 1/10 [03:31<31:47, 211.95s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  0.7569518476135599\n",
      "Validation Accuracy:  72.73371104815864 %\n",
      "Epoch Time:  211.95189428329468 s\n",
      "##################################################\n",
      "Epoch_Number:  1\n",
      "Training Loss:  0.6960300297734667\n",
      "Training Accuracy:  74.00814736096352 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 20%|████████████████████████████████▌                                                                                                                                  | 2/10 [07:04<28:19, 212.38s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  0.7359908754788121\n",
      "Validation Accuracy:  76.27478753541077 %\n",
      "Epoch Time:  212.66518592834473 s\n",
      "##################################################\n",
      "Epoch_Number:  2\n",
      "Training Loss:  0.6444695272758377\n",
      "Training Accuracy:  75.29814618018656 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 30%|████████████████████████████████████████████████▉                                                                                                                  | 3/10 [10:37<24:47, 212.45s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  0.7100117440494735\n",
      "Validation Accuracy:  77.97450424929178 %\n",
      "Epoch Time:  212.5309054851532 s\n",
      "##################################################\n",
      "Epoch_Number:  3\n",
      "Training Loss:  0.6121821825037902\n",
      "Training Accuracy:  76.3195182430039 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 40%|█████████████████████████████████████████████████████████████████▏                                                                                                 | 4/10 [14:09<21:15, 212.58s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  0.797478015501275\n",
      "Validation Accuracy:  76.55807365439094 %\n",
      "Epoch Time:  212.7759108543396 s\n",
      "##################################################\n",
      "Epoch_Number:  4\n",
      "Training Loss:  0.5678281517753565\n",
      "Training Accuracy:  77.09174636911087 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 50%|█████████████████████████████████████████████████████████████████████████████████▌                                                                                 | 5/10 [17:44<17:45, 213.16s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  1.0970313072018858\n",
      "Validation Accuracy:  72.80453257790369 %\n",
      "Epoch Time:  214.18588256835938 s\n",
      "##################################################\n",
      "Epoch_Number:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████████████████████████████████████████████▌                                                                                 | 5/10 [19:32<19:32, 234.49s/epoch]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mCNN2DSignal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ManufacturingNet/tutorials/../ManufacturingNet/models/CNN.py:645\u001b[0m, in \u001b[0;36mCNN2DSignal.__init__\u001b[0;34m(self, X, Y, shuffle)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_epoch()           \u001b[38;5;66;03m# getting an input for number oftraining epochs\u001b[39;00m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpochs: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumEpochs)\n\u001b[0;32m--> 645\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ManufacturingNet/tutorials/../ManufacturingNet/models/CNN.py:864\u001b[0m, in \u001b[0;36mCNN2DSignal.main\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    860\u001b[0m \u001b[38;5;66;03m# creating the validation dataset dataloader\u001b[39;00m\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdev_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[1;32m    862\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_data\u001b[38;5;241m.\u001b[39mget_batchsize())\n\u001b[0;32m--> 864\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m          \u001b[38;5;66;03m# training the model\u001b[39;00m\n\u001b[1;32m    866\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_loss_graph()           \u001b[38;5;66;03m# saving the loss graph\u001b[39;00m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion_input \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/ManufacturingNet/tutorials/../ManufacturingNet/models/CNN.py:938\u001b[0m, in \u001b[0;36mCNN2DSignal.train_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader):\n\u001b[1;32m    937\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 938\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    939\u001b[0m     target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    941\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet(data)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "CNN2DSignal(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright! Its done you have built your convolutional neural network using the manufacturingnet package. Just by answering a few simple questions. It is really easy\n",
    "\n",
    "The CNN signal is used if you want to manipulate your signal data and use it with CNN. It is a useful technique that we used in our other projects like bearing fault classification. It is important to note that tutorials are for demonstration purposes and hence in most of the tutorials we have trained for low number of epochs so results the results in tutorials may not represent the state-of-the art\n",
    "\n",
    "The model summary, training accuracy, validation accuracy, confusion matrix, Loss  vs epoch are also provided by the package."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robotics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "18cf912b356ea838ce5984d5dd427c109d0098d9758c1980ff8b664fe2b3a2be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
