{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using shallow learning algorithms from ManufacturingNet\n",
    "##### To know more about ManufacturingNet please visit: http://manufacturingnet.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ManufacturingNet\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import manufacturingnet. We can use this to experiment with several shallow learning models.\n",
    "\n",
    "It is important to note that all the dependencies of the package must also be installed in your environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now the dataset first needs to be downloaded. The dataset class can be used where different types of datasets have been curated and only two lines of code need to be run to download the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ManufacturingNet import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.ThreeDPrintingData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright! Now the dataset desired should be downloaded and present in the working directory.\n",
    "\n",
    "The 3D Printing dataset consists of several continuous and discrete parameters. We can perform classification or regression depending on what the desired output attribute is. We perform classification by predicting the material used based on the input and measured parameters. We can then perform regression on possibly a different attribute in the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset\n",
    "Here, we can use the pandas library to read and import the data, since there are categorial attributes. If pandas is not installed in your environment, here is a useful reference : https://pandas.pydata.org/docs/getting_started/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"3D_printing_dataset/data.csv\", sep = \",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then discretize the categorical attributes - infill pattern and material. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.material = [0 if each == \"abs\" else 1 for each in data.material]\n",
    "# abs = 0, pla = 1\n",
    "\n",
    "data.infill_pattern = [0 if each == \"grid\" else 1 for each in data.infill_pattern]\n",
    "# grid = 0, honeycomb = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For classification, we need the input data and an output variable to be predicted. \n",
    "We then separate our x and y values from the pandas dataframe. The value we want to predict is the \"material\", and our input data will be all the columns except \"material\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = data.material.values\n",
    "x_data = data.drop([\"material\"],axis=1).values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first get a birds-eye view of how the data can perform with some default classifiers. The metrics we use to measure the performance of these classifiers with some default values are Accuracy, 5-Fold cross validation, and the time. \n",
    "\n",
    "This will allow users to get a glance of how possible classifiers can perform on their data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ManufacturingNet.models import AllClassificationModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================\n",
      "= All Classifier Models Parameter Inputs =\n",
      "==========================================\n",
      "\n",
      "Enable verbose logging (y/N)? y\n",
      "verbose = True\n",
      "\n",
      "What fraction of the dataset should be used for testing (0,1)? 0.3\n",
      "test_size = 0.3\n",
      "\n",
      "===========================================\n",
      "= End of inputs; press enter to continue. =\n",
      "===========================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "d:\\anaconda3\\envs\\sharanpy3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "d:\\anaconda3\\envs\\sharanpy3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "d:\\anaconda3\\envs\\sharanpy3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "d:\\anaconda3\\envs\\sharanpy3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "d:\\anaconda3\\envs\\sharanpy3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "d:\\anaconda3\\envs\\sharanpy3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]\n",
      "===========\n",
      "= Results =\n",
      "===========\n",
      "\n",
      "Model                Accuracy             5-Fold CV Mean       Time (seconds)      \n",
      "\n",
      "LogisticRegression   1.0                  1.0                  0.03215217590332031 \n",
      "\n",
      "RandomForest         1.0                  0.96                 0.16355037689208984 \n",
      "\n",
      "SVC                  0.6                  0.6                  0.0059528350830078125\n",
      "\n",
      "NuSVC                1.0                  0.9800000000000001   0.0059871673583984375\n",
      "\n",
      "LinearSVC            1.0                  1.0                  0.003967761993408203\n",
      "\n",
      "XGBClassifier        1.0                  1.0                  0.016940593719482422\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\sharanpy3\\lib\\site-packages\\sklearn\\svm\\_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "d:\\anaconda3\\envs\\sharanpy3\\lib\\site-packages\\sklearn\\svm\\_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "d:\\anaconda3\\envs\\sharanpy3\\lib\\site-packages\\sklearn\\svm\\_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "d:\\anaconda3\\envs\\sharanpy3\\lib\\site-packages\\sklearn\\svm\\_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "d:\\anaconda3\\envs\\sharanpy3\\lib\\site-packages\\sklearn\\svm\\_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "d:\\anaconda3\\envs\\sharanpy3\\lib\\site-packages\\sklearn\\svm\\_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "all_models = AllClassificationModels(x_data, y_data)\n",
    "all_models.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the user wants to modify a particular classifier more specifically, they are free to choose the classifier they want and pass the data to that.\n",
    "\n",
    "The user can either choose to persist with the default parameters displayed or can customize the parameters according to their requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================================\n",
      "= RandomForestClassifier Parameter Inputs =\n",
      "===========================================\n",
      "\n",
      "Default values:\n",
      "test_size = 0.25\n",
      "cv = 5\n",
      "graph_results = False\n",
      "criterion = 'gini'\n",
      "class_weight = None\n",
      "n_estimators = 100\n",
      "max_depth = None\n",
      "min_samples_split = 2\n",
      "min_samples_leaf = 1\n",
      "min_weight_fraction_leaf = 0.0\n",
      "max_features = 'auto'\n",
      "max_leaf_nodes = None\n",
      "min_impurity_decrease = 0.0\n",
      "bootstrap = True\n",
      "oob_score = False\n",
      "n_jobs = None\n",
      "random_state = None\n",
      "verbose = 0\n",
      "warm_start = False\n",
      "ccp_alpha = 0.0\n",
      "max_samples = None\n",
      "\n",
      "Use default parameters (Y/n)? n\n",
      "\n",
      "If you are unsure about a parameter, press enter to use its default value.\n",
      "If you finish entering parameters early, enter 'q' to skip ahead.\n",
      "\n",
      "\n",
      "What fraction of the dataset should be the testing set (0,1)? 0.3\n",
      "test_size = 0.3\n",
      "\n",
      "Use GridSearch to find the best hyperparameters (y/N)? n\n",
      "\n",
      "Enter the number of folds for cross validation [2,): 4\n",
      "cv = 4\n",
      "\n",
      "Graph the ROC curve? Only binary classification is supported (y/N): n\n",
      "graph_results = False\n",
      "\n",
      "Enter a positive number of trees for the forest: 5\n",
      "n_estimators = 5\n",
      "\n",
      "Which criteria should be used for measuring split quality?\n",
      "Enter 1 for 'gini' or 2 for 'entropy': 2\n",
      "criterion = entropy\n",
      "\n",
      "Automatically balance the class weights (y/N)? y\n",
      "class_weight = balanced\n",
      "\n",
      "Enter a positive maximum tree depth.\n",
      "Press enter for no maximum depth: \n",
      "max_depth = None\n",
      "\n",
      "Enter min_samples_split, a positive minimum number of samples required to split an internal node: q\n",
      "min_samples_split = 2\n",
      "\n",
      "===========================================\n",
      "= End of inputs; press enter to continue. =\n",
      "===========================================\n",
      "\n",
      "\n",
      "==================================\n",
      "= RandomForestClassifier Results =\n",
      "==================================\n",
      "\n",
      "Classes:\n",
      " [0 1]\n",
      "\n",
      "Accuracy:            0.8                 \n",
      "\n",
      "ROC AUC:             1.0                 \n",
      "\n",
      "Cross Validation Scores: [0.92307692 0.92307692 0.83333333 1.        ]\n",
      "\n",
      "Feature Importances: [0.01899263 0.0483097  0.11320588 0.15000321 0.28586981 0.01804133\n",
      " 0.01388688 0.03980425 0.06259568 0.10829455 0.14099607]\n",
      "\n",
      "\n",
      "Call predict_classifier() to make predictions for new data.\n",
      "\n",
      "===================\n",
      "= End of results. =\n",
      "===================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ManufacturingNet.models import RandomForest\n",
    "\n",
    "rf_model = RandomForest(x_data, y_data)\n",
    "\n",
    "rf_model.run_classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For regression, we need the input data and an output value to be obtained. \n",
    "We then separate our x and y values from the pandas dataframe. In this example, the value we want to output is the \"roughness\", and our input data will be all the columns except \"roughness\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data_lin = data.roughness.values\n",
    "x_data_lin = data.drop([\"roughness\"],axis=1).values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first get a birds-eye view of how the data can perform with some default regression models. The metrics we use to measure the performance of these regression models with some default parameters are R-2 score and the time taken to run the algorithm. \n",
    "\n",
    "This will allow users to get a glance of how possible regression models can perform on their data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================\n",
      "= All Regression Models Parameter Inputs =\n",
      "==========================================\n",
      "\n",
      "\n",
      "Enable verbose logging (y/N)? y\n",
      "verbose = True\n",
      "\n",
      "What fraction of the dataset should be used for testing (0,1)? 0.3\n",
      "test_size = 0.3\n",
      "\n",
      "===========================================\n",
      "= End of inputs; press enter to continue. =\n",
      "===========================================\n",
      "\n",
      "[LibSVM][LibSVM][LibLinear]\n",
      "===========\n",
      "= Results =\n",
      "===========\n",
      "\n",
      "Model                R2 Score             Time (seconds)      \n",
      "\n",
      "LinearRegression     0.7839528897180778   0.0009965896606445312\n",
      "\n",
      "RandomForest         0.7286256946765022   0.15658211708068848 \n",
      "\n",
      "SVR                  -0.3089653305411606  0.001996278762817383\n",
      "\n",
      "NuSVR                -0.3455457990858901  0.0009965896606445312\n",
      "\n",
      "LinearSVR            -1.1582988832961658  0.003989458084106445\n",
      "\n",
      "XGBRegressor         0.6152293548509122   0.023934364318847656\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "d:\\anaconda3\\envs\\sharanpy3\\lib\\site-packages\\sklearn\\svm\\_base.py:975: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from ManufacturingNet.models import AllRegressionModels\n",
    "\n",
    "models_reg = AllRegressionModels(x_data_lin, y_data_lin)\n",
    "models_reg.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the user wants to modify a particular regression model more specifically, they are free to choose the model they want and pass the data to that.\n",
    "\n",
    "The user can either choose to persist with the default parameters displayed or can customize the parameters according to their requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================\n",
      "= LinRegression Parameter Inputs =\n",
      "==================================\n",
      "\n",
      "Default values:\n",
      "test_size = 0.25\n",
      "cv = 5\n",
      "graph_results = False\n",
      "fit_intercept = True\n",
      "normalize = False\n",
      "copy_X = True\n",
      "n_jobs = None\n",
      "\n",
      "Use default parameters (Y/n)? n\n",
      "\n",
      "If you are unsure about a parameter, press enter to use its default value.\n",
      "If you finish entering parameters early, enter 'q' to skip ahead.\n",
      "\n",
      "What fraction of the dataset should be the testing set (0,1)? 0.3\n",
      "test_size = 0.3\n",
      "\n",
      "Enter the number of folds for cross validation [2,): 4\n",
      "cv = 4\n",
      "\n",
      "Include a y-intercept in the model (Y/n)? y\n",
      "fit_intercept = True\n",
      "\n",
      "Normalize the dataset (y/N)? y\n",
      "normalize = True\n",
      "\n",
      "Copy the dataset's features (Y/n)? y\n",
      "copy_X = True\n",
      "\n",
      "Enter a positive number of CPU cores to use: 1\n",
      "n_jobs = 1\n",
      "\n",
      "===========================================\n",
      "= End of inputs; press enter to continue. =\n",
      "===========================================\n",
      "\n",
      "\n",
      "=========================\n",
      "= LinRegression Results =\n",
      "=========================\n",
      "\n",
      "Coefficients:\n",
      " [ 1.43922399e+03  2.72533590e+00 -1.06612868e-01 -2.62514622e+00\n",
      "  1.42579384e+01 -8.00135057e+00  5.53519193e-01  2.86363338e+02\n",
      " -1.60027011e+00  7.24157778e-01 -2.27783434e+01]\n",
      "\n",
      "Intercept:           -2660.7746627755114 \n",
      "\n",
      "Mean Squared Error:  908.1472964823573   \n",
      "\n",
      "R2 Score:            0.9069302524142602  \n",
      "\n",
      "R Score:             0.9523288572831657  \n",
      "\n",
      "Cross Validation Scores:\n",
      " [-3.29300656  0.40752238  0.38569189  0.14808594]\n",
      "\n",
      "\n",
      "Call predict() to make predictions for new data.\n",
      "\n",
      "===================\n",
      "= End of results. =\n",
      "===================\n",
      "\n",
      "MSE: 908.1472964823573\n",
      "R2: 0.9069302524142602\n",
      "R: 0.9523288572831657\n"
     ]
    }
   ],
   "source": [
    "from ManufacturingNet.models import LinRegression as LinReg\n",
    "\n",
    "\n",
    "model_lin = LinReg(x_data_lin, y_data_lin)\n",
    "model_lin.run()\n",
    "\n",
    "print(\"MSE:\", model_lin.get_mean_squared_error())\n",
    "print(\"R2:\", model_lin.get_r2_score())\n",
    "print(\"R:\", model_lin.get_r_score())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how we can use ManufacturingNet to accomplish classification and regression tasks. \n",
    "We can first obtain a birds-eye view of the performance of all the models that can be used with our data. If we want to modify  a particular model specifically for our data, we can customize the parameters for the model of our choice."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "2469a70536e4d2335a2ea8907942d0699c37342a371ac185bdb5b0aa6f073890"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
