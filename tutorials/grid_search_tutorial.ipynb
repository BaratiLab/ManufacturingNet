{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning hyper-parameters using Grid Search and ManufacturingNet\n",
    "##### To learn more about ManufacturingNet, please visit http://manufacturingnet.io/.\n",
    "\n",
    "In this tutorial, we will use Grid Search to tune the hyper-parameters of a XGBoost regression model trained on the Mercedes-Benz Greener Manufacturing dataset included in ManufacturingNet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ManufacturingNet import datasets\n",
    "from ManufacturingNet.models import XGBoost\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the datasets and XGBoost modules from ManufacturingNet. The former will help us download and prepare the Mercedes-Benz Greener Manufacturing dataset, and the latter will provide the XGBoost model. We'll also import numpy to read in the dataset.\n",
    "\n",
    "\n",
    "\n",
    "###### It is important to note that all of the package's dependencies must be installed in your environment. Check the documentation for a comprehensive list of ManufacturingNet's dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download the dataset, simply call the MercedesData() method in the datasets module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.MercedesData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please check your working directory; if you see a new folder called \"Mercedes_files,\" the method worked!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Mercedes-Benz Greener Manufacturing dataset contains many permutations of Mercedes-Benz vehicle features; these features include whether a car has four-wheel drive, air suspension, or a heads-up display. Your task is to predict how much time a car will spend on the test bench given its features. In this tutorial, we will tackle this using an XGBoost regression model.\n",
    "\n",
    "The Mercedes_files/ folder in your working directory contains two files: merc_features.npy, and merc_labels.npy. The former contains the cars' features, and the latter contains the time spent testing each car. We use the numpy module's load() method to load each file into the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('./Mercedes_files/merc_features.npy', allow_pickle = True)\n",
    "Y = np.load('./Mercedes_files/merc_labels.npy', allow_pickle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can create the XGBoost model. To instantiate the model, we simply call the XGBoost constructor, and pass in our features and labels from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBoost(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing Hyper-Parameters with Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start building the model, we call the run_regressor() method on our XGBoost model. When this line runs, a command-line interface in your terminal will guide you through the parameter inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interface will first ask you if you'd like to use all default values. To use Grid Search, we input 'n' to continue to parameter inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first parameter, test_size, enter your preferred testing set size, or press enter to continue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When prompted to use Grid Search, we input 'y'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we may select multiple boosters, learning rates, gamma values, tree amounts, and tree depths to try. We have entered some potential candidates below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After finding the optimal permutation of hyper-parameters, Grid Search will save these values, and the model's parameter inputs will continue. For simplicity's sake, we'll use default values for the remaining inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================\n",
      "= XGBRegressor Parameter Inputs =\n",
      "=================================\n",
      "\n",
      "Default values:\n",
      "test_size = 0.25\n",
      "cv = 5\n",
      "objective = 'reg:squarederror'\n",
      "n_estimators = 100\n",
      "max_depth = 3\n",
      "learning_rate = 0.1\n",
      "booster = 'gbtree'\n",
      "n_jobs = 1\n",
      "nthread = None\n",
      "gamma = 0\n",
      "min_child_weight = 1\n",
      "max_delta_step = 0\n",
      "subsample = 1\n",
      "colsample_bytree = 1\n",
      "colsample_bylevel = 1\n",
      "reg_alpha = 0\n",
      "reg_lambda = 1\n",
      "scale_pos_weight = 1\n",
      "base_score = 0.5\n",
      "random_state = 42\n",
      "missing = None\n",
      "verbosity = False\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Use default parameters (Y/n)?  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "If you are unsure about a parameter, press enter to use its default value.\n",
      "If you finish entering parameters early, enter 'q' to skip ahead.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "What fraction of the dataset should be the testing set (0,1)?  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_size = 0.25\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Use GridSearch to find the best hyperparameters (y/N)?  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "= GridSearch Parameter Inputs =\n",
      "\n",
      "Enter 'q' to skip GridSearch.\n",
      "\n",
      "Enter the types of boosters.\n",
      "Options: 1-'gbtree', 2-'gblinear' or 3-'dart'. Enter 'all' for all options.\n",
      "Example input: 1,2,3\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 1,3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boosters: ['gbtree', 'dart']\n",
      "\n",
      "Enter a list of learning rates to try out.\n",
      "Example input: 0.1,0.01,0.001\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 0.1,0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rates: [0.1, 0.01]\n",
      "\n",
      "Enter a list of gamma values/minimum loss reductions to try out.\n",
      "Example input: 0.5,1,1.5\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gammas: [0.5]\n",
      "\n",
      "Enter a list of number of trees to try out.\n",
      "Example input: 1,2,3\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators: [100]\n",
      "\n",
      "Enter a list of max tree depths to try out.\n",
      "Example input: 1,2,3\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 3,4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depths: [3, 4]\n",
      "\n",
      "= End of GridSearch inputs. =\n",
      "\n",
      "\n",
      "Best GridSearch Parameters:\n",
      " {'booster': 'dart', 'gamma': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100} \n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter the number of folds for cross validation [2,):  q\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv = None\n",
      "\n",
      "===========================================\n",
      "= End of inputs; press enter to continue. =\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "===========================================\n",
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================\n",
      "= XGBRegressor Results =\n",
      "========================\n",
      "\n",
      "Mean Squared Error:  64.53131275651117   \n",
      "\n",
      "R2 Score:            0.5664428235586155  \n",
      "\n",
      "R Score:             0.7526239589320921  \n",
      "\n",
      "Cross Validation Scores: [0.43206355 0.43682215 0.59214757 0.54374362 0.4988061 ]\n",
      "\n",
      "Feature Importances: [3.4976748e-03 3.1012250e-03 2.1990235e-03 2.6222060e-03 1.4178248e-03\n",
      " 0.0000000e+00 2.4875063e-03 1.9911753e-03 3.2474571e-03 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 1.5964758e-03 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.7632935e-03 2.6914261e-03\n",
      " 0.0000000e+00 0.0000000e+00 1.5125168e-03 0.0000000e+00 0.0000000e+00\n",
      " 2.2695516e-03 2.7928289e-03 8.3022177e-02 0.0000000e+00 5.5022151e-03\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 2.7438751e-03 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 8.4623070e-03 2.2385695e-03 6.3477730e-04 5.6067770e-03 0.0000000e+00\n",
      " 3.8269758e-03 0.0000000e+00 8.3312569e-03 0.0000000e+00 0.0000000e+00\n",
      " 2.3915214e-03 1.1592517e-03 0.0000000e+00 0.0000000e+00 5.3081498e-03\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 4.3330099e-03 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 2.8983210e-03 0.0000000e+00 2.7930364e-03\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.4245993e-03 4.5136809e-03\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.4685584e-03 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 1.9645502e-03 2.6940345e-03 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 3.7699086e-03 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 1.4850042e-03 1.2038467e-03 0.0000000e+00\n",
      " 3.2234002e-02 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 8.8427857e-02 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 2.2779282e-03 1.7820108e-03 0.0000000e+00\n",
      " 0.0000000e+00 1.9583851e-03 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 9.0635126e-04 5.5315509e-04\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 1.6435803e-03 1.9803704e-03 0.0000000e+00 3.1560488e-04\n",
      " 3.7055849e-03 4.9877060e-03 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 3.3875537e-04 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 4.3282644e-03 0.0000000e+00 0.0000000e+00 2.2568647e-03 0.0000000e+00\n",
      " 5.1532369e-03 4.9855551e-03 3.1633906e-03 5.9318645e-03 0.0000000e+00\n",
      " 4.9651000e-03 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 2.6529739e-03 0.0000000e+00 3.7953094e-02 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.2561187e-03\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.2011492e-03\n",
      " 0.0000000e+00 1.5347170e-03 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 5.0376263e-03 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 8.4956959e-03 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 4.1252417e-03\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 5.8011417e-03\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0481335e-02\n",
      " 0.0000000e+00 0.0000000e+00 5.8304407e-03 0.0000000e+00 0.0000000e+00\n",
      " 2.5798045e-03 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 3.8068191e-04 0.0000000e+00 4.5690611e-03 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 3.6132280e-03 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 1.3492608e-03 0.0000000e+00 6.2051984e-03 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.8540017e-03 1.2141318e-03\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.3898812e-03\n",
      " 0.0000000e+00 4.1843620e-01 4.6722196e-02 3.6852858e-03 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.4646579e-03 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.9861865e-03\n",
      " 0.0000000e+00 2.1617473e-03 0.0000000e+00 1.7554103e-03 0.0000000e+00\n",
      " 0.0000000e+00 2.8544615e-03 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 1.1682315e-03 4.0017436e-03 1.8794379e-03\n",
      " 0.0000000e+00 0.0000000e+00 3.0505329e-03 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 1.7503714e-03 8.0207782e-03 4.0841210e-03 0.0000000e+00\n",
      " 0.0000000e+00 2.0801804e-03 4.3310239e-03 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 1.4043989e-03 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.2701807e-03 0.0000000e+00\n",
      " 1.6474442e-03 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.8584291e-03\n",
      " 0.0000000e+00 0.0000000e+00]\n",
      "\n",
      "GridSearch Score:    0.6018342481911515  \n",
      "\n",
      "\n",
      "Call predict_regressor() to make predictions for new data.\n",
      "\n",
      "===================\n",
      "= End of results. =\n",
      "===================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.run_regressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training the model, we can see how the XGBoost model performed with optimal hyper-parameters.\n",
    "To keep the processing time reasonable, we were quite conservative with which hyper-parameter values to try. In real-world usage, you may want to try many more values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you have a trained XGBoost model with optimal hyper-parameters, courtesy of Grid Search! To check which ManufacturingNet models support Grid Search, visit our documentation: https://manufacturingnet.readthedocs.io/en/latest/."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
