{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning hyper-parameters using Grid Search and ManufacturingNet\n",
    "##### To learn more about ManufacturingNet, please visit http://manufacturingnet.io/.\n",
    "\n",
    "In this tutorial, we will use Grid Search to tune the hyper-parameters of a XGBoost regression model trained on the Mercedes-Benz Greener Manufacturing dataset included in ManufacturingNet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ManufacturingNet import datasets\n",
    "from ManufacturingNet.models import XGBoost\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the datasets and XGBoost modules from ManufacturingNet. The former will help us download and prepare the Mercedes-Benz Greener Manufacturing dataset, and the latter will provide the XGBoost model. We'll also import numpy to read in the dataset.\n",
    "\n",
    "\n",
    "\n",
    "###### It is important to note that all of the package's dependencies must be installed in your environment. Check the documentation for a comprehensive list of ManufacturingNet's dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download the dataset, simply call the MercedesData() method in the datasets module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.MercedesData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please check your working directory; if you see a new folder called \"Mercedes_files,\" the method worked!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Mercedes-Benz Greener Manufacturing dataset contains many permutations of Mercedes-Benz vehicle features; these features include whether a car has four-wheel drive, air suspension, or a heads-up display. Your task is to predict how much time a car will spend on the test bench given its features. In this tutorial, we will tackle this using an XGBoost regression model.\n",
    "\n",
    "The Mercedes_files/ folder in your working directory contains two files: merc_features.npy, and merc_labels.npy. The former contains the cars' features, and the latter contains the time spent testing each car. We use the numpy module's load() method to load each file into the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('./Mercedes_files/merc_features.npy', allow_pickle = True)\n",
    "Y = np.load('./Mercedes_files/merc_labels.npy', allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4209, 377), (4209,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can create the XGBoost model. To instantiate the model, we simply call the XGBoost constructor, and pass in our features and labels from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBoost(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing Hyper-Parameters with Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start building the model, we call the run_regressor() method on our XGBoost model. When this line runs, a command-line interface in your terminal will guide you through the parameter inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interface will first ask you if you'd like to use all default values. To use Grid Search, we input 'n' to continue to parameter inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first parameter, test_size, enter your preferred testing set size, or press enter to continue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When prompted to use Grid Search, we input 'y'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we may select multiple boosters, learning rates, gamma values, tree amounts, and tree depths to try. We have entered some potential candidates below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After finding the optimal permutation of hyper-parameters, Grid Search will save these values, and the model's parameter inputs will continue. For simplicity's sake, we'll use default values for the remaining inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================\n",
      "= XGBRegressor Parameter Inputs =\n",
      "=================================\n",
      "\n",
      "Default values:\n",
      "test_size = 0.25\n",
      "cv = 5\n",
      "objective = 'reg:squarederror'\n",
      "n_estimators = 100\n",
      "max_depth = 3\n",
      "learning_rate = 0.1\n",
      "booster = 'gbtree'\n",
      "n_jobs = 1\n",
      "nthread = None\n",
      "gamma = 0\n",
      "min_child_weight = 1\n",
      "max_delta_step = 0\n",
      "subsample = 1\n",
      "colsample_bytree = 1\n",
      "colsample_bylevel = 1\n",
      "reg_alpha = 0\n",
      "reg_lambda = 1\n",
      "scale_pos_weight = 1\n",
      "base_score = 0.5\n",
      "random_state = 42\n",
      "missing = None\n",
      "verbosity = False\n",
      "\n",
      "===========================================\n",
      "= End of inputs; press enter to continue. =\n",
      "\n",
      "========================\n",
      "= XGBRegressor Results =\n",
      "========================\n",
      "\n",
      "Mean Squared Error:  81.68839381759616   \n",
      "\n",
      "R2 Score:            0.45861473867391755 \n",
      "\n",
      "R Score:             0.6772110001129025  \n",
      "\n",
      "Cross Validation Scores: [0.11195188 0.41239833 0.55263934 0.44356911 0.12363461]\n",
      "\n",
      "Feature Importances: [1.06024847e-03 9.47052264e-04 7.07946427e-04 9.37720819e-04\n",
      " 8.95637553e-04 8.46140611e-05 9.96407354e-04 1.42492901e-03\n",
      " 1.06600905e-03 8.85898189e-04 0.00000000e+00 2.32540374e-03\n",
      " 3.23586282e-03 8.75728903e-04 5.87974282e-05 9.35813703e-04\n",
      " 0.00000000e+00 6.28970447e-04 1.51379546e-03 1.35877973e-03\n",
      " 0.00000000e+00 1.13253272e-03 1.30173611e-03 0.00000000e+00\n",
      " 5.24301489e-04 1.94168719e-03 0.00000000e+00 1.41695246e-01\n",
      " 2.90323340e-04 2.32836092e-03 0.00000000e+00 0.00000000e+00\n",
      " 2.35377938e-05 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 5.40917157e-04 0.00000000e+00 1.69636027e-04 0.00000000e+00\n",
      " 0.00000000e+00 7.01998651e-04 9.54444695e-04 3.65520100e-04\n",
      " 6.81051402e-04 4.96713631e-03 0.00000000e+00 1.33007672e-03\n",
      " 1.74618652e-03 9.39367688e-04 7.17558665e-04 0.00000000e+00\n",
      " 0.00000000e+00 1.11652922e-03 2.24543866e-04 2.86899478e-04\n",
      " 8.91332573e-04 0.00000000e+00 0.00000000e+00 1.12577691e-03\n",
      " 0.00000000e+00 5.63718437e-04 1.42874836e-03 1.80339906e-03\n",
      " 0.00000000e+00 0.00000000e+00 2.00214796e-03 1.80665916e-03\n",
      " 1.54917489e-03 1.94232038e-03 1.21980009e-03 5.80787273e-05\n",
      " 1.46262301e-03 0.00000000e+00 7.89106998e-04 0.00000000e+00\n",
      " 1.07610086e-03 0.00000000e+00 4.30206303e-04 6.32585492e-04\n",
      " 0.00000000e+00 0.00000000e+00 9.38103418e-04 9.44731641e-04\n",
      " 0.00000000e+00 6.45575929e-04 0.00000000e+00 0.00000000e+00\n",
      " 2.83981557e-04 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.27794675e-03 1.04588002e-03 5.51576377e-04 2.94821861e-04\n",
      " 0.00000000e+00 8.45299277e-04 0.00000000e+00 0.00000000e+00\n",
      " 5.39595552e-04 1.78313965e-03 7.53282977e-04 6.83329185e-04\n",
      " 0.00000000e+00 0.00000000e+00 1.01118628e-03 7.13293266e-04\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 9.33234289e-04\n",
      " 1.53778412e-03 1.13174005e-03 7.78343412e-04 3.42803858e-02\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 9.53777271e-05\n",
      " 0.00000000e+00 4.71234525e-04 0.00000000e+00 1.41395153e-02\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00421661e-03\n",
      " 3.74302239e-04 6.68589899e-04 0.00000000e+00 1.11195364e-03\n",
      " 0.00000000e+00 6.74953568e-04 1.09287270e-03 1.06972957e-03\n",
      " 3.74609837e-03 5.99452993e-04 1.19345088e-03 2.15218030e-03\n",
      " 4.83545125e-04 3.47910216e-04 0.00000000e+00 0.00000000e+00\n",
      " 9.13671509e-04 1.64278888e-03 1.34222559e-03 8.09723977e-04\n",
      " 0.00000000e+00 7.15496368e-04 9.27885820e-04 1.23592396e-03\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 4.65679877e-05\n",
      " 6.59263169e-04 0.00000000e+00 1.06713525e-03 2.62644095e-03\n",
      " 8.18948960e-04 1.16031915e-04 0.00000000e+00 1.20390416e-03\n",
      " 0.00000000e+00 3.14186880e-04 4.95270768e-04 0.00000000e+00\n",
      " 2.45784147e-04 4.14412876e-04 5.22166549e-04 7.72298721e-04\n",
      " 9.97083262e-04 1.55426702e-03 0.00000000e+00 9.64333012e-04\n",
      " 6.92907197e-04 1.18825305e-03 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.07235974e-03 1.17302276e-04 4.18378375e-02\n",
      " 0.00000000e+00 2.06702249e-03 4.84541612e-04 0.00000000e+00\n",
      " 5.14231564e-04 2.06195889e-03 3.73761548e-04 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.46780058e-03 1.09913744e-04\n",
      " 7.38480827e-04 0.00000000e+00 0.00000000e+00 4.78422327e-04\n",
      " 0.00000000e+00 5.71210345e-04 8.30407545e-04 0.00000000e+00\n",
      " 0.00000000e+00 2.33872241e-04 0.00000000e+00 0.00000000e+00\n",
      " 1.32552208e-03 0.00000000e+00 0.00000000e+00 9.45482112e-04\n",
      " 5.39306435e-04 1.22650794e-03 0.00000000e+00 0.00000000e+00\n",
      " 1.55263650e-03 7.33335211e-04 5.55636827e-04 0.00000000e+00\n",
      " 0.00000000e+00 5.20305592e-04 0.00000000e+00 5.79353771e-04\n",
      " 1.13865803e-03 0.00000000e+00 0.00000000e+00 1.04146707e-03\n",
      " 0.00000000e+00 5.50466590e-03 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 2.19453080e-03 1.25924184e-03 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 6.87665888e-04\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 9.47549881e-04\n",
      " 3.06079339e-04 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.09054068e-04\n",
      " 0.00000000e+00 0.00000000e+00 1.42475581e-02 0.00000000e+00\n",
      " 0.00000000e+00 3.87437089e-04 0.00000000e+00 0.00000000e+00\n",
      " 8.09219375e-04 0.00000000e+00 0.00000000e+00 4.72860811e-05\n",
      " 1.92777123e-04 0.00000000e+00 1.49959850e-03 5.06067008e-04\n",
      " 1.78781338e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 3.60302161e-04\n",
      " 8.05342221e-04 2.71876401e-04 5.08646306e-04 0.00000000e+00\n",
      " 1.30970194e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.90431034e-04 4.98995592e-04 0.00000000e+00 1.64512836e-03\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 8.61119071e-04\n",
      " 0.00000000e+00 7.22518773e-04 1.07688783e-03 0.00000000e+00\n",
      " 1.92881344e-04 1.05548080e-03 2.58583087e-03 1.90318460e-04\n",
      " 0.00000000e+00 0.00000000e+00 5.57859137e-04 6.42873114e-04\n",
      " 0.00000000e+00 1.12495909e-03 4.96125430e-01 3.97146679e-02\n",
      " 1.52325339e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.05563155e-03 1.50306302e-03 3.68648180e-04\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.62431190e-03\n",
      " 0.00000000e+00 3.61699332e-03 0.00000000e+00 0.00000000e+00\n",
      " 1.15269846e-04 2.94063881e-04 4.01467754e-04 0.00000000e+00\n",
      " 8.57100647e-04 2.28649145e-03 6.92322734e-04 4.19113552e-03\n",
      " 1.20084535e-03 5.12091618e-04 1.18650962e-03 4.96690453e-04\n",
      " 1.77771715e-03 1.40085141e-03 1.34584401e-03 0.00000000e+00\n",
      " 0.00000000e+00 1.51608721e-03 7.01145444e-04 1.95777509e-03\n",
      " 8.30811448e-04 5.21390582e-04 8.48747382e-04 4.86999197e-04\n",
      " 8.54856044e-04 0.00000000e+00 2.95352726e-03 6.41519728e-04\n",
      " 0.00000000e+00 0.00000000e+00 3.92264890e-04 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.62057194e-03 2.52424012e-04 0.00000000e+00 1.02808932e-04\n",
      " 0.00000000e+00 5.65042894e-04 1.07976364e-03 1.39067404e-03\n",
      " 1.57576951e-03 3.00159678e-03 2.27590659e-04 0.00000000e+00\n",
      " 7.31172680e-04 0.00000000e+00 2.06549838e-03 0.00000000e+00\n",
      " 0.00000000e+00]\n",
      "\n",
      "\n",
      "Call predict_regressor() to make predictions for new data.\n",
      "\n",
      "===================\n",
      "= End of results. =\n",
      "===================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.run_regressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training the model, we can see how the XGBoost model performed with optimal hyper-parameters.\n",
    "To keep the processing time reasonable, we were quite conservative with which hyper-parameter values to try. In real-world usage, you may want to try many more values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you have a trained XGBoost model with optimal hyper-parameters, courtesy of Grid Search! To check which ManufacturingNet models support Grid Search, visit our documentation: https://manufacturingnet.readthedocs.io/en/latest/."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
