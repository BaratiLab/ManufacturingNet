from sklearn import linear_model
from sklearn.metrics import accuracy_score, roc_auc_score
from sklearn.model_selection import train_test_split
import numpy as np

class LogisticRegression: 
    
    """
    Wrapper class around scikit-learn's logistic regression functionality.

    Logistic Regression is a type of Generalized Linear Model (GLM) that uses a logistic function to model a binary 
    variable based on any kind of independent variables.
    """


    def __init__(self, dataset = None, attributes = None, labels = None, test_size = None, penalty='l2', dual=False, \
                    tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, \
                        solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None):
        

        """
        Initializes a LogisticRegression object.

        The following parameters are needed to create a logistic regression model:

            - dataset: a populated pandas DataFrame object
            - attributes: a list of the column headers for the desired independent variables
            - labels: a list of the column headers for the desired dependent variables
            - test_size: the proportion of the dataset to be used for testing the model (defaults to 0.25);
            the proportion of the dataset to be used for training will be the complement of test_size
            - fit_intercept: specifies if a constant (a.k.a. bias or intercept) should be added to the decision function. (defaults to True)
            - intercept_scaling: used only when the solver ‘liblinear’ is used and self.fit_intercept is set to True. Here, x becomes [x, self.intercept_scaling], 
            i.e. a “synthetic” feature with constant value equal to intercept_scaling is appended to the instance vector.
            - class_weight: weights associated with classes (defaults to None). If set to 'balanced' then the values of y are used 
             to automatically adjust weights inversely proportional to class frequencies in the input data.
            - random_state: used when solver == ‘sag’, ‘saga’ or ‘liblinear’ to shuffle the data (defaults to None)
            - solver: chooses the algorithm for the optimization problem, (defaults to lbfgs)
            - max_iter: maximum number of iterations taken for the solvers to converge (defaults to 100)
            - multi_class: chooses if we fit a binary problem or a multi-class problem for each label (defaults to auto)
            - verbose: used in the liblinear or lbfgs solvers, where any positive number is set (defaults to 0)
            - warm_start: when set to true, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution (defaults to False)
            - n_jobs: the number of jobs to use for the computation (defaults to None)
            - l1_ratio: this is the Elastic-Net mixing parameter. Setting this to 0 is using l2 penalty, setting this to
            1 is using l1_penalty and a value between 0 and 1 is a combination of l1 and l2. 

        The following instance data is found after successfully running linear_regression():

            - coefficients: an array of coefficients that most closely satisfy the linear relationship between the
            independent and dependent variables
            - intercept: the y-intercept of the regression line generated by the model
            - classes: a list of class labels known to the classifier
            - n_iter : Actual number of iterations for all classes.
            - accuracy: the classification accuracy score
            - roc_auc: the area under the receiver operating characteristic curve from the prediction scores
        """



        self.dataset = dataset
        self.attributes = attributes
        self.labels = labels

        self.test_size = test_size
        self.penalty = penalty
        self.dual = dual
        self.tol = tol
        self.C = C

        self.fit_intercept = fit_intercept
        self.intercept_scaling = intercept_scaling
        self.class_weight = class_weight

        self.random_state = random_state
        self.solver = solver
        self.max_iter = max_iter
        self.multi_class = multi_class

        self.verbose = verbose
        self.warm_start = warm_start
        self.n_jobs = n_jobs
        self.l1_ratio = l1_ratio

        self.classes_ = None
        self.coef_ = None
        self.intercept_ = None
        self.n_iter_ = None

        self.accuracy = None
        self.precision = None
        self.recall = None
        self.roc_auc = None

    # Accessor methods

    def get_dataset(self):
        """
        Accessor method for dataset.

        If a LogisticRegression object is constructed without specifying dataset, dataset will be None.
        logistic_regression() cannot be called until dataset is a populated pandas DataFrame; call set_dataset(new_dataset)
        """
        return self.dataset

    def get_attributes(self):
        """
        Accessor method for attributes.

        If a LogisticRegression object is constructed without specifying attributes, attributes will be None.
        logistic_regression() cannot be called until attributes is a list of your attributes' names; call
        set_attributes(new_attributes) to fix this.
        """
        return self.attributes

    def get_labels(self):
        """
        Accessor method for labels.

        If a LogisticRegression object is constructed without specifying labels, labels will be None.
        logistic_regression() cannot be called until labels is a list of your labels' names; call set_labels(new_labels)
        to fix this.
        """
        return self.labels

    
    def get_classes(self):
        """
        Accessor method for classes.

        Will return None if linear_regression() hasn't been called, yet.
        """
        return self.classes


    def get_coefficents(self):
        """
        Accessor method for coefficients.

        Will return None if linear_regression() hasn't been called, yet.
        """
        return self.coef_

    def get_n_iter_(self):
        """
        Accessor method for number of iterations for all classes.

        Will return None if linear_regression() hasn't been called, yet.
        """
        return self.n_iter_

    def get_accuracy(self):
        """
        Accessor method for accuracy.

        Will return None if linear_regression() hasn't been called, yet.
        """
        return self.accuracy

    def get_roc_auc(self):
        """
        Accessor method for roc-auc score.

        Will return None if linear_regression() hasn't been called, yet.
        """
        return self.roc_auc


    def set_dataset(self, new_dataset = None):
        """
        Modifier method for dataset.

        Input should be a populated DataFrame object.
        """
        self.dataset = new_dataset

    def set_attributes(self, new_attributes = None):
        """
        Modifier method for attributes.

        Input should be a list of strings, where each string is the name of an independent variable.
        """
        self.attributes = new_attributes

    def set_labels(self, new_labels = None):
        """
        Modifier method for labels.

        Input should be a list of strings, where each string is the name of a dependent variable.
        """
        self.labels = new_labels

    def set_test_size(self, new_test_size = None):
        """
        Modifier method for train_test_split.

        Input should be a list of strings, where each string is the name of a dependent variable.
        """
        self.test_size  = new_test_size


    # Wrapper for logistic regression model

    def logistic_regression(self):
        """
        Performs logistic regression on dataset using scikit-learn's logistic_model and returns the resultant array of
        coefficients.
        """
        if self._check_inputs():
            # Instantiate LogisticRegression() object
            regression = linear_model.LogisticRegression(penalty=self.penalty, dual=self.dual, tol=self.tol, \
                C=self.C, fit_intercept=self.fit_intercept, intercept_scaling=self.intercept_scaling, class_weight=self.class_weight, \
                    random_state=self.random_state, solver=self.solver, max_iter=self.max_iter, multi_class=self.multi_class, \
                        verbose=self.verbose, warm_start=self.warm_start, n_jobs=self.n_jobs, l1_ratio=self.l1_ratio)

            # Extract attributes and labels from dataset
            dataset_X = self.dataset[self.attributes]
            dataset_y = self.dataset[self.labels]


            # Split into training and testing set
            dataset_X_train, dataset_X_test, dataset_y_train, dataset_y_test = \
                train_test_split(dataset_X,dataset_y,test_size=self.test_size)

            # Train the model and get resultant coefficients
            regression.fit(dataset_X_train, np.ravel(dataset_y_train))

            # Get resultant coefficients and intercept of regression line
            self.classes_ = regression.classes_
            self.coefficients = regression.coef_
            self.intercept = regression.intercept_
            self.n_iter_ = regression.n_iter_


            # Make predictions using testing set
            y_prediction = regression.predict(dataset_X_test)
            y_pred_probas = regression.predict_proba(dataset_X_test)[::, 1]

            #Metrics
            self.accuracy = accuracy_score(y_prediction, dataset_y_test)
            self.roc_auc = roc_auc_score(y_prediction, y_pred_probas)


    # Helper method for checking inputs

    def _check_inputs(self):
        """
        Verifies if dataset, attributes, and labels are ready for use in logistic regression model.
        """

        # Check if dataset exists
        if self.dataset is None:
            print("dataset is missing; call set_dataset(new_dataset) to fix this!")
            return False

        # Check if attributes exists
        if not self.attributes:
            print("attributes is missing; call set_attributes(new_attributes) to fix this! new_attributes should be a",
            "list of the names of your attributes.")
            return False

        # Check if labels exists
        if not self.labels:
            print("labels is missing; call set_labels(new_labels) to fix this! new_labels should be a list of the names",
            "of your labels.")
            return False

        if not self.test_size:
            print("test_size is missing; call set_test_size(new_test_size) to fix this! ")
            return False

        # Check if attributes consists of valid column headers This is done by checking if attributes is a subset of
        # dataset's column headers
        if not all(att in self.dataset.columns.values for att in self.attributes):
            print("attributes contains one or more attribute that isn't in dataset; call set_attributes(new_attributes)",
            "to fix this, where new_attributes only contains valid independent variables.")
            return False

        # Check if labels consists of valid column headers
        if not all(label in self.dataset.columns.values for label in self.labels):
            print("labels contains one or more label that isn't in dataset; call set_labels(new_label) to fix this,",
            "where new_labels contains only valid dependent variables.")
            return False

        return True
